- hosts: all
  become: yes
  roles:
    - install-openjdk
    - create-single-k8s-cluster-with-kubeadm
  tasks:
    - name: Login dockerhub
      shell: docker login -u {{ dockerhub.username }} -p {{ dockerhub.password }}
      no_log: yes

    - name: Run integration tests of Spark with k8s cluster manager
      shell: |
        set -ex

        sed -i -e '/127.0.0.1/ s/\(localhost\)/'$(hostname)' \1/' /etc/hosts

        # Create required account in k8s
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl create serviceaccount spark
        kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=default

        # NOTE: the distribution step may fail due to dependencies downloading failure, so we support retry
        for i in $(seq 1 3); do ./dev/make-distribution.sh --tgz -Pkubernetes && s=0 && break || s=$? && sleep 5; done; (exit $s)

        pushd resource-managers/kubernetes/integration-tests
        dev/dev-run-integration-tests.sh --deploy-mode cloud \
            --spark-master k8s://$(kubectl config view -o jsonpath='{.clusters[0].cluster.server}') \
            --spark-tgz $(realpath ../../../spark-*.tgz) --image-repo '{{ dockerhub.username }}' \
            --namespace default --service-account spark --r-image-name spark-r --exclude-tags minikube
        popd
      args:
        executable: /bin/bash
        chdir: '{{ zuul.project.src_dir }}'
      environment: '{{ global_env }}'
