- name: Set up Kubernetes local cluster
  hosts: all
  become: yes
  gather_facts: no
  tasks:
    - name: Set up Kubernetes local cluster
      shell:
        cmd: |
          set -e
          set -x
          apt-get install python-pip -y
          pip install -U python-openstackclient

          # NOTE: the following commands may include sensitive information please do not print in job logs
          export OS_PASSWORD="`echo {{ telekom_credentials.password }}`"
          export OS_AUTH_TYPE="`echo {{ telekom_credentials.auth_type }}`"
          export OS_AUTH_URL="`echo {{ telekom_credentials.auth_url }}`"
          export OS_IDENTITY_API_VERSION="`echo {{ telekom_credentials.identity_api_version }}`"
          export OS_DOMAIN_NAME="`echo {{ telekom_credentials.domain_name }}`"
          export OS_PROJECT_NAME="`echo {{ telekom_credentials.project_name}}`"
          export OS_REGION_NAME="`echo {{ telekom_credentials.region_name}}`"
          export OS_TENANT_NAME="`echo {{ telekom_credentials.project_name }}`"
          export OS_USERNAME="`echo {{ telekom_credentials.user_name }}`"
          export OS_ACCESS_KEY="`echo {{ telekom_credentials.access_key }}`"
          export OS_SECRET_KEY="`echo {{ telekom_credentials.secret_key }}`"

          # Build cloud-provider-openstack binaries
          go get github.com/Masterminds/glide
          make depend
          make build

          # Build K8S
          go env
          go version
          go get -u github.com/jteeuwen/go-bindata/go-bindata || true
          go get -u github.com/cloudflare/cfssl/cmd/... || true
          # Get Kubernetes from source
          mkdir -p ${GOPATH}/src/k8s.io/
          if [ ! -d "${GOPATH}/src/k8s.io/kubernetes" ]; then
              git clone https://github.com/kubernetes/kubernetes ${GOPATH}/src/k8s.io/kubernetes
              pushd ${GOPATH}/src/k8s.io/kubernetes >/dev/null
              git remote update
              git fetch --all --tags --prune
              popd >/dev/null
          fi
          make -C ${GOPATH}/src/k8s.io/kubernetes WHAT="cmd/kubectl cmd/hyperkube"

          if [[ ! -d "/etc/kubernetes/" ]]; then
              sudo mkdir -p /etc/kubernetes/
          fi
          chown ubuntu /etc/kubernetes/
          cat << EOF >> /etc/kubernetes/cloud-config
          [Global]
          domain-name= ${OS_DOMAIN_NAME}
          tenant-name = ${OS_TENANT_NAME}
          auth-url = ${OS_AUTH_URL}
          password = ${OS_PASSWORD}
          username = ${OS_USERNAME}
          region = ${OS_REGION_NAME}
          # [LoadBalancer]
          # floating-network-id = "{{ floating_network_id }}"
          # subnet-id = "{{ subnet_id }}"
          [BlockStorage]
          bs-version = v2
          EOF
          # Install Make
          apt-get install make -y
          # Install docker
          if ! dpkg -s "docker-engine" > /dev/null 2> /dev/null; then
              sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609
              sudo apt-key adv --keyserver hkp://pgp.mit.edu:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D || true
              sudo apt-add-repository 'deb http://apt.dockerproject.org/repo ubuntu-xenial main'
              sudo apt-get update -y
              sudo apt-cache policy docker-engine
              sudo apt-get install -y docker-engine=1.12.6-0~ubuntu-xenial
              sudo cat /lib/systemd/system/docker.service
              sudo sed -r -i "s|(ExecStart)=(.+)|\1=\2 --iptables=false|" /lib/systemd/system/docker.service
              sudo cat /lib/systemd/system/docker.service
              sudo systemctl daemon-reload
              sudo systemctl restart docker
              sudo systemctl status docker
              sudo ifconfig -a
          fi
          docker --version
          # Get the latest stable version of kubernetes
          export K8S_VERSION=$(curl -sS https://storage.googleapis.com/kubernetes-release/release/stable.txt)
          echo "K8S_VERSION : ${K8S_VERSION}"
          echo "Starting docker service"
          sudo systemctl enable docker.service
          sudo systemctl start docker.service --ignore-dependencies
          echo "Checking docker service"
          sudo docker ps
          wget -c https://github.com/coreos/etcd/releases/download/v3.3.0/etcd-v3.3.0-linux-amd64.tar.gz
          tar xzvf etcd-v3.3.0-linux-amd64.tar.gz
          cp etcd-v3.3.0-linux-amd64/etcd /usr/local/bin/
          cp etcd-v3.3.0-linux-amd64/etcdctl /usr/local/bin/

          source openrc
          mkdir -p "{{ ansible_user_dir }}/.kube"
          # Debuging ...
          export API_HOST_IP="172.17.0.1"
          export KUBELET_HOST="0.0.0.0"
          export WAIT_FOR_URL_API_SERVER=120
          echo "Stopping firewall and allow all traffic..."
          iptables -F
          iptables -X
          iptables -t nat -F
          iptables -t nat -X
          iptables -t mangle -F
          iptables -t mangle -X
          iptables -P INPUT ACCEPT
          iptables -P FORWARD ACCEPT
          iptables -P OUTPUT ACCEP
          export ALLOW_SECURITY_CONTEXT=true
          export ENABLE_CRI=false
          export ENABLE_HOSTPATH_PROVISIONER=true
          export ENABLE_SINGLE_CA_SIGNER=true
          # export KUBE_ENABLE_CLUSTER_DASHBOARD=true
          export KUBE_ENABLE_CLUSTER_DNS=false
          export LOG_LEVEL=10
          # go where we cloned kubernetes repository
          cd $GOPATH/src/k8s.io/kubernetes
          # we want to use the openstack cloud provider
          export CLOUD_PROVIDER=openstack
          # we want to run a separate cloud-controller-manager for openstack
          export EXTERNAL_CLOUD_PROVIDER=true
          # DO NOT change the location of the cloud-config file. It's important for the old cinder provider to work
          export CLOUD_CONFIG=/etc/kubernetes/cloud-config
          # specify the OCCM binary
          export EXTERNAL_CLOUD_PROVIDER_BINARY="{{ ansible_user_dir }}/src/github.com/liu-sheng/openstack-cloud-controller-manager/openstack-cloud-controller-manager
          # Kill existing processes
          ps -ef | grep -i -e etcd -e hyperkube | grep -v grep | awk '{print $2}' | xargs sudo kill -9
          # Cleanup some directories just in case
          sudo rm -rf /var/lib/kubelet/
          # location of where the kubernetes processes log their output
          mkdir -p /opt/stack/logs/
          export LOG_DIR=/opt/stack/logs
          # We need this for one of the conformance tests
          export ALLOW_PRIVILEGED=true
          # Just kick off all the processes and drop down to the command line
          export ENABLE_DAEMON=true
          # We need the hostname to match the name of the vm started by openstack
          export HOSTNAME_OVERRIDE=$(hostname)
          # export HOSTNAME_OVERRIDE=$(ip route get 1.1.1.1 | awk '{print $7}'
          # Add other paths we usually keep stuff in
          export PATH=$GOPATH/bin:${PATH}:/opt/stack/bin
          sed 's/curl --max-time 1/curl --max-time 5/g' -i ./hack/lib/util.sh
          # -E preserves the current env vars, but we need to special case PATH
          sudo -E PATH=$PATH SHELLOPTS=$SHELLOPTS ./hack/local-up-cluster.sh -
          # sudo of local-up-cluster mucks with permissions
          sudo chmod -R 777 /home/ubuntu/.kube
          sudo chmod 777 /var/run/kubernetes/client-admin.ke
          # set up the config we need for kubectl to work
          cluster/kubectl.sh config set-cluster local --server=https://localhost:6443 --certificate-authority=/var/run/kubernetes/server-ca.crt
          cluster/kubectl.sh config set-credentials myself --client-key=/var/run/kubernetes/client-admin.key --client-certificate=/var/run/kubernetes/client-admin.crt
          cluster/kubectl.sh config set-context local --cluster=local --user=myself
          cluster/kubectl.sh config use-context loca
          # Hack for RBAC for all for the new cloud-controller process, we need to do better than this
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:default kube-system-cluster-admin-1 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:pvl-controller kube-system-cluster-admin-2 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:cloud-node-controller kube-system-cluster-admin-3 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:cloud-controller-manager kube-system-cluster-admin-4 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:shared-informers kube-system-cluster-admin-5 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:kube-controller-manager  kube-system-cluster-admin-6 --clusterrole cluster-admin
          TESTARGS='-v' make test 2>&1
        executable: /bin/bash
        chdir: '{{ zuul.project.src_dir }}'
      environment: '{{ golang_env }}'