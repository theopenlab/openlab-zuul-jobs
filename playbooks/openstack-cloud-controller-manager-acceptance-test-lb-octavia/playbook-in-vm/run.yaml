- name: Add server to inventory
  hosts: localhost
  become: yes
  tasks:
    - name: Add server to inventory
      add_host:
        name: "{{ server_name }}"
        ansible_host: "{{ server_ip }}"
        ansible_user: "ubuntu"
        ansible_ssh_private_key_file: "{{ key_file }}"
        ansible_python_interpreter: /usr/bin/python3

- name: Prepare for local cluster
  hosts: "{{ server_name }}"
  become: yes
  gather_facts: no
  tasks:
    - shell:
        cmd: |
          set -e
          set -x
          cat << EOF >> ./openrc
          export OS_PROJECT_DOMAIN_ID=default
          export OS_REGION_NAME=RegionOne
          export OS_USER_DOMAIN_ID=default
          export OS_PROJECT_NAME=admin
          export OS_IDENTITY_API_VERSION=3
          export OS_PASSWORD=secretadmin
          export OS_AUTH_TYPE=password
          export OS_AUTH_URL="http://{{ devstack_ip }}/identity"
          export OS_USERNAME=admin
          export OS_TENANT_NAME=admin
          export OS_VOLUME_API_VERSION=2
          EOF
          source ./openrc

          if [[ ! -d "/etc/kubernetes/" ]]; then
              sudo mkdir -p /etc/kubernetes/
          fi
          chown ubuntu /etc/kubernetes/

          cat << EOF >> /etc/kubernetes/cloud-config
          [Global]
          domain-id = default
          tenant-id = "{{ project_id }}"
          auth-url = ${OS_AUTH_URL}
          password = secretadmin
          username = admin
          region = RegionOne

          [LoadBalancer]
          floating-network-id = "{{ floating_network_id }}"
          subnet-id = "{{ subnet_id }}"

          [BlockStorage]
          bs-version = v2
          EOF

          # Install Make
          apt-get install make -y

          # Install docker
          if ! dpkg -s "docker-engine" > /dev/null 2> /dev/null; then
              sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D || true
              sudo apt-key adv --keyserver hkp://pgp.mit.edu:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D || true
              sudo apt-add-repository 'deb http://apt.dockerproject.org/repo ubuntu-xenial main'
              sudo apt-get update -y
              sudo apt-cache policy docker-engine
              sudo apt-get install -y docker-engine=1.12.6-0~ubuntu-xenial
              sudo cat /lib/systemd/system/docker.service
              sudo sed -r -i "s|(ExecStart)=(.+)|\1=\2 --iptables=false|" /lib/systemd/system/docker.service
              sudo cat /lib/systemd/system/docker.service
              sudo systemctl daemon-reload
              sudo systemctl restart docker
              sudo systemctl status docker
              sudo ifconfig -a
          fi
          docker --version

          # Get the latest stable version of kubernetes
          export K8S_VERSION=$(curl -sS https://storage.googleapis.com/kubernetes-release/release/stable.txt)
          echo "K8S_VERSION : ${K8S_VERSION}"

          echo "Starting docker service"
          sudo systemctl enable docker.service
          sudo systemctl start docker.service --ignore-dependencies
          echo "Checking docker service"
          sudo docker ps

          wget -c https://github.com/coreos/etcd/releases/download/v3.3.0/etcd-v3.3.0-linux-amd64.tar.gz
          tar xzvf etcd-v3.3.0-linux-amd64.tar.gz
          cp etcd-v3.3.0-linux-amd64/etcd /usr/local/bin/
          cp etcd-v3.3.0-linux-amd64/etcdctl /usr/local/bin/

        executable: /bin/bash
      environment:
        GOPATH: '{{ ansible_user_dir }}'
        PATH: '/usr/local/go/bin:{{ ansible_user_dir }}/bin:{{ ansible_env.PATH }}'

- name: Set up Kubernetes local cluster
  hosts: "{{ server_name }}"
  become: yes
  gather_facts: no
  tasks:
   - name: Set up Kubernetes local cluster
     block:
       - shell:
           cmd: |
             # set -e
             set -x
             export PATH="/usr/local/go/bin:{{ ansible_user_dir }}/bin:${PATH}"
             export GOPATH="{{ ansible_user_dir }}"
             source openrc
             mkdir -p /home/ubuntu/.kube

             # Debuging ...
             export API_HOST_IP="172.17.0.1"
             export KUBELET_HOST="0.0.0.0"
             export WAIT_FOR_URL_API_SERVER=120


             echo "Stopping firewall and allow all traffic..."
             iptables -F
             iptables -X
             iptables -t nat -F
             iptables -t nat -X
             iptables -t mangle -F
             iptables -t mangle -X
             iptables -P INPUT ACCEPT
             iptables -P FORWARD ACCEPT
             iptables -P OUTPUT ACCEPT

             export ALLOW_SECURITY_CONTEXT=true
             export ENABLE_CRI=false
             export ENABLE_HOSTPATH_PROVISIONER=true
             export ENABLE_SINGLE_CA_SIGNER=true
             # export KUBE_ENABLE_CLUSTER_DASHBOARD=true
             export KUBE_ENABLE_CLUSTER_DNS=false
             export LOG_LEVEL=4

             # go where we cloned kubernetes repository
             cd $GOPATH/src/k8s.io/kubernetes/

             # we want to use the openstack cloud provider
             export CLOUD_PROVIDER=openstack
             # we want to run a separate cloud-controller-manager for openstack
             export EXTERNAL_CLOUD_PROVIDER=true
             # DO NOT change the location of the cloud-config file. It's important for the old cinder provider to work
             export CLOUD_CONFIG=/etc/kubernetes/cloud-config
             # specify the OCCM binary
             export EXTERNAL_CLOUD_PROVIDER_BINARY="{{ ansible_user_dir }}/src/github.com/liu-sheng/openstack-cloud-controller-manager/openstack-cloud-controller-manager"

             # Kill existing processes
             ps -ef | grep -i -e etcd -e hyperkube | grep -v grep | awk '{print $2}' | xargs sudo kill -9
             # Cleanup some directories just in case
             sudo rm -rf /var/lib/kubelet/*

             # location of where the kubernetes processes log their output
             mkdir -p /opt/stack/logs/
             export LOG_DIR=/opt/stack/logs
             # We need this for one of the conformance tests
             export ALLOW_PRIVILEGED=true
             # Just kick off all the processes and drop down to the command line
             export ENABLE_DAEMON=true
             # We need the hostname to match the name of the vm started by openstack
             export HOSTNAME_OVERRIDE=$(hostname)
             # export HOSTNAME_OVERRIDE=$(ip route get 1.1.1.1 | awk '{print $7}')

             # Add other paths we usually keep stuff in
             export PATH=$GOPATH/bin:${PATH}:/opt/stack/bin:

             # sed '582 a \    sleep 7200'  -i ./hack/local-up-cluster.sh
             # sed '582,589d' -i ./hack/local-up-cluster.sh
             sed 's/curl --max-time 1/curl --max-time 5/g' -i ./hack/lib/util.sh
             # -E preserves the current env vars, but we need to special case PATH
             sudo -E PATH=$PATH SHELLOPTS=$SHELLOPTS ./hack/local-up-cluster.sh -O

             # sudo of local-up-cluster mucks with permissions
             sudo chmod -R 777 /home/ubuntu/.kube
             sudo chmod 777 /var/run/kubernetes/client-admin.key

             # set up the config we need for kubectl to work
             cluster/kubectl.sh config set-cluster local --server=https://localhost:6443 --certificate-authority=/var/run/kubernetes/server-ca.crt
             cluster/kubectl.sh config set-credentials myself --client-key=/var/run/kubernetes/client-admin.key --client-certificate=/var/run/kubernetes/client-admin.crt
             cluster/kubectl.sh config set-context local --cluster=local --user=myself
             cluster/kubectl.sh config use-context local

             # Hack for RBAC for all for the new cloud-controller process, we need to do better than this
             cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:default kube-system-cluster-admin-1 --clusterrole cluster-admin
             cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:pvl-controller kube-system-cluster-admin-2 --clusterrole cluster-admin
             cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:cloud-node-controller kube-system-cluster-admin-3 --clusterrole cluster-admin
             cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:cloud-controller-manager kube-system-cluster-admin-4 --clusterrole cluster-admin
             cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:shared-informers kube-system-cluster-admin-5 --clusterrole cluster-admin
             cluster/kubectl.sh create clusterrolebinding --user system:kube-controller-manager  kube-system-cluster-admin-6 --clusterrole cluster-admin
             # sleep 7200
           executable: /bin/bash
     always:
       - shell:
           cmd: |
             set -e
             set -x
             echo "Collecting Kubernetes logs ..."
             mkdir -p "{{ ansible_user_dir }}/workspace/logs/kubernetes"
             rsync -az -e "ssh -i {{ key_file }}" "ubuntu@{{ server_ip }}:/opt/stack/logs/*" "{{ ansible_user_dir }}/workspace/logs/kubernetes/"
             rsync -az -e "ssh -i {{ key_file }}" "ubuntu@{{ server_ip }}:/etc/kubernetes/*" "{{ ansible_user_dir }}/workspace/logs/kubernetes/"
           executable: /bin/bash
         delegate_to: localhost
     environment:
       GOPATH: '{{ ansible_user_dir }}'
       PATH: '/usr/local/go/bin:{{ ansible_user_dir }}/bin:{{ ansible_env.PATH }}'
