- hosts: k8s-master
  become: yes
  roles:
    - role: deploy-k8s-cluster-with-kubeadm
      k8s_role_to_deploy:
        - master
  tasks:
    - name: get kubeadm join command
      shell: kubeadm token create --print-join-command
      register: kubeadm_join_cmd

- hosts: k8s-nodes
  become: yes
  roles:
    - role: deploy-k8s-cluster-with-kubeadm
      k8s_role_to_deploy:
        - node
      kubeadm_join_cmd: "{{ hostvars['k8s-master']['kubeadm_join_cmd']['stdout'] }}"

- hosts: k8s-master
  become: yes
  tasks:
    - name: config PVs for kubeflow
      shell:
        cmd: |
          set -ex
          apt-get install -y nfs-server
          export KUBECONFIG=/etc/kubernetes/admin.conf
          for i in `seq 1 3`;do
              mkdir -p /nfs-data/kubeflow-pv$i
              echo "/nfs-data/kubeflow-pv$i *(rw,sync,no_root_squash,no_subtree_check)" >> /etc/exports
              systemctl restart nfs-kernel-server.service
              cat << EOF >> kubeflow-pv$i.yaml
              apiVersion: v1
              kind: PersistentVolume
              metadata:
                name: kubeflow-pv$i
              spec:
                capacity:
                  storage: 20Gi
                accessModes:
                  - ReadWriteOnce
                nfs:
                  server: {{ ansible_host }}
                  path: /nfs-data/kubeflow-pv$i
          EOF
              kubectl create -f kubeflow-pv$i.yaml
          done
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'

    - name: prepare k8s namespaces
      shell:
        cmd: |
          set -ex
          sleep 10
          kubectl get nodes
          kubectl wait --timeout 300s --for condition=ready node --all
          kubectl label node k8s-master env=system
          for node in "{{ groups['k8s-nodes']|join(' ') }}"; do
              kubectl label node ${node} env=workload
          done

          cat <<EOF | kubectl create -f -
          apiVersion: v1
          kind: Namespace
          metadata:
           name: kubeflow
           annotations:
             scheduler.alpha.kubernetes.io/node-selector: env=system
          spec: {}
          status: {}
          EOF

          cat <<EOF | kubectl create -f -
          apiVersion: v1
          kind: Namespace
          metadata:
           name: tf-benchmarks
           annotations:
             scheduler.alpha.kubernetes.io/node-selector: env=workload
          spec: {}
          status: {}
          EOF
          CURRENT_CONTEXT=$(kubectl config current-context)
          CURRENT_CLUSTER=$(kubectl config get-contexts $CURRENT_CONTEXT | tail -1 | awk '{print $3}')
          CURRENT_USER=$(kubectl config get-contexts $CURRENT_CONTEXT | tail -1 | awk '{print $4}')
          kubectl config set-context tf-benchmarks \
            --namespace tf-benchmarks \
            --cluster $CURRENT_CLUSTER \
            --user $CURRENT_USER
        executable: /bin/bash

    - name: deploy kubeflow and run tensorflow benchmarks
      shell: |
        set -ex
        wget https://github.com/kubeflow/kubeflow/releases/download/v0.5.0/kfctl_v0.5.0_linux.tar.gz
        tar -zxvf kfctl_*.tar.gz -C /usr/local/bin/
        export KFAPP="kfapp"
        kfctl init ${KFAPP} -v v0.5.0
        pushd ${KFAPP}
        kfctl generate all -V
        kfctl apply all -V
        kubectl -n kubeflow get all -o wide
        popd
        # pushd ${KFAPP}
        # kfctl delete all --delete_storage
        # popd

        kubectl -n kubeflow wait --timeout 300s --for condition=ready pod --all


        wget https://github.com/ksonnet/ksonnet/releases/download/v0.13.1/ks_0.13.1_linux_amd64.tar.gz
        tar -zxvf ks_*.tar.gz
        cp ks_0.13.1_linux_amd64/ks /usr/local/bin/
        export CNN_JOB_NAME=tfcnnbenchmarks
        export KF_VERSION=v0.5.0
        export KF_ENV=default
        # workaround for API limit error of Github, see:
        # https://github.com/ksonnet/ksonnet/blob/master/docs/troubleshooting.md#github-rate-limiting-errors
        export GITHUB_TOKEN=c0250b662cfa40845058626ca47eb5accb586d27
        ks init ${CNN_JOB_NAME} --context tf-benchmarks
        pushd ${CNN_JOB_NAME}
        ks registry add kubeflow github.com/kubeflow/kubeflow/tree/${KF_VERSION}/kubeflow
        ks pkg install kubeflow/examples
        ks prototype list
        for i in $(seq 1 3); do
            ks generate tf-job-simple-v1beta2 ${CNN_JOB_NAME}-${i} --name=${CNN_JOB_NAME}-${i}
        done
        ks apply ${KF_ENV}
        ks component list
        kubectl -n tf-benchmarks get pods -o wide
        kubectl -n tf-benchmarks get tfjobs -o wide
        sleep 100000000000


        function tfjobs_status() {
            kubectl -n tf-benchmarks get tfjobs --no-headers | awk '{print $2}'|uniq
        }
        export -f tfjobs_status
        timeout 7200 bash -c '
            while :
            do
                job_status=$(tfjobs_status)
                if [[ ${job_status} == Running ]]; then
                    echo "Waiting for TF jobs running..."
                elif echo ${job_status} |grep Failed;
                    echo "Some TFjobs has failed :("
                    kubectl -n tf-benchmarks get tfjobs -o wide
                    exit 1
                elif [[ ${job_status} == Succeeded ]]; then
                   echo "TFjobs running Succeeded :)"
                   kubectl -n tf-benchmarks get tfjobs -o wide
                   break
                fi
                sleep 30
            done
            '

        mkdir -p '{{ ansible_user_dir }}/workspace/test_results/tfjobs/'
        job_pods = $(kubectl -n tf-benchmarks get pods -o custom-columns=NAME:.metadata.name --no-headers |grep benchmark)
        for job_pod in ${job_pods}; do
            kubectl -n tf-benchmarks logs ${job_pod} > "{{ ansible_user_dir }}/workspace/test_results/tfjobs/${job_pod}.log"
        done

        ks delete ${KF_ENV}
        popd
        rm -fr ${CNN_JOB_NAME}
      args:
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
