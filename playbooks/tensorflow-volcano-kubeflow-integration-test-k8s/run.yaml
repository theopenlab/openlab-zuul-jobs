- hosts: k8s-master
  become: yes
  roles:
    - role: deploy-k8s-cluster-with-kubeadm
      k8s_role_to_deploy:
        - master
  tasks:
    - name: get kubeadm join command
      shell: kubeadm token create --print-join-command
      register: kubeadm_join_cmd

- hosts: k8s-node-1,k8s-node-2
  become: yes
  roles:
    - role: deploy-k8s-cluster-with-kubeadm
      k8s_role_to_deploy:
        - node
      kubeadm_join_cmd: "{{ hostvars['k8s-master']['kubeadm_join_cmd']['stdout'] }}"

- hosts: k8s-master
  become: yes
  tasks:
    - name: config PVs for kubeflow
      shell:
        cmd: |
          set -ex
          apt-get install -y nfs-server
          export KUBECONFIG=/etc/kubernetes/admin.conf
          for i in `seq 1 3`;do
              mkdir -p /nfs-data/kubeflow-pv$i
              echo "/nfs-data/kubeflow-pv$i *(rw,sync,no_root_squash,no_subtree_check)" >> /etc/exports
              systemctl restart nfs-kernel-server.service
              cat << EOF >> kubeflow-pv$i.yaml
              apiVersion: v1
              kind: PersistentVolume
              metadata:
                name: kubeflow-pv$i
              spec:
                capacity:
                  storage: 20Gi
                accessModes:
                  - ReadWriteOnce
                nfs:
                  server: {{ ansible_host }}
                  path: /nfs-data/kubeflow-pv$i
          EOF
              kubectl create -f kubeflow-pv$i.yaml
          done
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'

    - name: deploy kubeflow
      shell: |
        set -ex
        wget https://github.com/kubeflow/kubeflow/releases/download/v0.5.0/kfctl_v0.5.0_linux.tar.gz
        tar -zxvf kfctl_*.tar.gz -C /usr/local/bin/
        export KFAPP="kfapp"
        kfctl init ${KFAPP} -v v0.5.0
        pushd ${KFAPP}
        kfctl generate all -V
        kfctl apply all -V
        kubectl -n kubeflow get all -o wide
        popd
        # pushd ${KFAPP}
        # kfctl delete all --delete_storage
        # popd

        timeout 300 bash -c '
        while :
        do
            [ -z "$(kubectl -n kubeflow get pods --field-selector=status.phase!=Running)" ] && break
            sleep 5
        done
        '

        kubectl create namespace tf-benchmarks

        CURRENT_CONTEXT=$(kubectl config current-context)
        CURRENT_CLUSTER=$(kubectl config get-contexts $CURRENT_CONTEXT | tail -1 | awk '{print $3}')
        CURRENT_USER=$(kubectl config get-contexts $CURRENT_CONTEXT | tail -1 | awk '{print $4}')
        kubectl config set-context tf-benchmarks \
          --namespace tf-benchmarks \
          --cluster $CURRENT_CLUSTER \
          --user $CURRENT_USER

        wget https://github.com/ksonnet/ksonnet/releases/download/v0.13.1/ks_0.13.1_linux_amd64.tar.gz
        tar -zxvf ks_*.tar.gz
        cp ks_0.13.1_linux_amd64/ks /usr/local/bin/
        CNN_JOB_NAME=tfcnnbenchmarks
        KF_VERSION=v0.5.0
        export KF_ENV=default
        # workaround for API limit error of Github, see:
        # https://github.com/ksonnet/ksonnet/blob/master/docs/troubleshooting.md#github-rate-limiting-errors
        export GITHUB_TOKEN=c0250b662cfa40845058626ca47eb5accb586d27
        ks init ${CNN_JOB_NAME} --context tf-benchmarks
        pushd ${CNN_JOB_NAME}
        ks registry add kubeflow-git github.com/kubeflow/kubeflow/tree/${KF_VERSION}/kubeflow
        ks pkg install kubeflow-git/examples
        ks prototype list
        ks generate tf-job-simple-v1beta2 ${CNN_JOB_NAME} --name=${CNN_JOB_NAME}
        ks apply ${KF_ENV} -c ${CNN_JOB_NAME}

        timeout 300 bash -c '
        while :
        do
            [ -z "$(kubectl -n tf-benchmarks get pods --field-selector=status.phase!=Running)" ] && break
            sleep 5
        done
        '

        kubectl -n tf-benchmarks logs ${CNN_JOB_NAME}-worker-0 -f || true
        ks delete ${KF_ENV} -c ${CNN_JOB_NAME}
        popd

      args:
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
